{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "team_c10_res.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "stem_cell": {
      "cell_type": "raw",
      "source": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Jul 21 21:17:48 2019\n\n@author: Junfeng Hu\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport argparse\n#from resnet import ResNet18\nimport torch.nn.functional as F\n#CUDA_VISIBLE_DEVICES\u003d2\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inchannel, outchannel, stride\u003d1):\n        super(ResidualBlock, self).__init__()\n        self.left \u003d nn.Sequential(\n            nn.Conv2d(inchannel, outchannel, kernel_size\u003d3, stride\u003dstride, padding\u003d1, bias\u003dFalse),\n            nn.BatchNorm2d(outchannel),\n            nn.ReLU(inplace\u003dTrue),\n            nn.Conv2d(outchannel, outchannel, kernel_size\u003d3, stride\u003d1, padding\u003d1, bias\u003dFalse),\n            nn.BatchNorm2d(outchannel)\n        )\n        self.shortcut \u003d nn.Sequential()\n         # 如果输入和输出的通道不一致，或其步长不为 1，需要将二者转成一致\n        if stride !\u003d 1 or inchannel !\u003d outchannel:\n            self.shortcut \u003d nn.Sequential(\n                nn.Conv2d(inchannel, outchannel, kernel_size\u003d1, stride\u003dstride, bias\u003dFalse),\n                nn.BatchNorm2d(outchannel)\n            )\n\n    def forward(self, x):\n        out \u003d self.left(x)\n        out +\u003d self.shortcut(x)# 输出 + 输入\n        out \u003d F.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, ResidualBlock, num_classes\u003d10):\n        super(ResNet, self).__init__()\n        self.inchannel \u003d 64\n        self.conv1 \u003d nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size\u003d3, stride\u003d1, padding\u003d1, bias\u003dFalse),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n        )\n        #ResNet 包含多个 layer, 每个 layer 又包含多个 residual block (上面实现的类)\n        #因此, 用 ResidualBlock 实现 Residual 部分，用 _make_layer 函数实现 layer\n        #四个 layer， 对应 2， 3， 4， 5 层， 每层有两个 residual block\n        self.layer1 \u003d self.make_layer(ResidualBlock, 64,  2, stride\u003d1)\n        self.layer2 \u003d self.make_layer(ResidualBlock, 128, 2, stride\u003d2)\n        self.layer3 \u003d self.make_layer(ResidualBlock, 256, 2, stride\u003d2)\n        self.layer4 \u003d self.make_layer(ResidualBlock, 512, 2, stride\u003d2)\n        # 最后的全连接，分类时使用\n        self.fc \u003d nn.Linear(512, num_classes)\n\n    def make_layer(self, block, channels, num_blocks, stride):\n        #构建 layer, 每一个 layer 由多个 residual block 组成\n        #在 ResNet 中，每一个 layer 中只有两个 residual block\n        strides \u003d [stride] + [1] * (num_blocks - 1)   #strides\u003d[1,1]\n        layers \u003d []\n        for stride in strides:\n            layers.append(block(self.inchannel, channels, stride))\n            self.inchannel \u003d channels\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # 最开始的处理\n        out \u003d self.conv1(x)\n        # 四层 layer\n        out \u003d self.layer1(out)\n        out \u003d self.layer2(out)\n        out \u003d self.layer3(out)\n        out \u003d self.layer4(out)\n        # 全连接 输出分类信息\n        out \u003d F.avg_pool2d(out, 4)\n        out \u003d out.view(out.size(0), -1)\n        out \u003d self.fc(out)\n        return out\n\n\ndef ResNet18():\n\n    return ResNet(ResidualBlock)\n\n\n# 定义是否使用GPU\ndevice \u003d torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# 参数设置,使得我们能够手动输入命令行参数\nparser \u003d argparse.ArgumentParser(description\u003d\u0027PyTorch CIFAR10 Training\u0027)\nparser.add_argument(\u0027--outf\u0027, default\u003d\u0027./model/\u0027, help\u003d\u0027folder to output images and model checkpoints\u0027) #输出结果保存路径\nparser.add_argument(\u0027--net\u0027, default\u003d\u0027./model/Resnet18.pth\u0027, help\u003d\"path to net (to continue training)\")  #恢复训练时的模型路径\nargs \u003d parser.parse_args()\n\n# 超参数设置\nEPOCH \u003d 20   #遍历数据集次数\npre_epoch \u003d 0  # 定义已经遍历数据集的次数\nBATCH_SIZE \u003d 128      #批处理尺寸(batch_size)\nLR \u003d 0.1        #学习率\n# 准备数据集并预处理\ntransform_train \u003d transforms.Compose([\n    transforms.RandomCrop(32, padding\u003d4),  #先四周填充0，在吧图像随机裁剪成32*32(cifar10)  #mnist:28*28\n    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n    transforms.ToTensor(),\n    transforms.Normalize(mean\u003d[0.4914, 0.4822, 0.4465],std\u003d[0.2023, 0.1994, 0.2010])])   # mnist: mean\u003d[0.49],std\u003d[1]\n\ntrainset \u003d torchvision.datasets.CIFAR10(root\u003d\u0027./data\u0027, train\u003dTrue, download\u003dTrue, transform\u003dtransform_train) #训练数据集\ntrainloader \u003d torch.utils.data.DataLoader(trainset, batch_size\u003dBATCH_SIZE, shuffle\u003dTrue, num_workers\u003d1)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n\ntransform_test \u003d transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntestset \u003d torchvision.datasets.CIFAR10(root\u003d\u0027./data\u0027, train\u003dFalse, download\u003dTrue, transform\u003dtransform_test)\ntestloader \u003d torch.utils.data.DataLoader(testset, batch_size\u003d100, shuffle\u003dFalse, num_workers\u003d1)\n\n# 模型定义-ResNet\nnet \u003d ResNet18().cuda()\n\n# 定义损失函数和优化方式\ncriterion \u003d nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\noptimizer \u003d optim.SGD(net.parameters(), lr\u003dLR, momentum\u003d0.9, weight_decay\u003d5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n\n# 训练\nfor epoch in range(pre_epoch, EPOCH):\n    print(\u0027\\nEpoch: %d\u0027 % (epoch + 1))\n    net.train()\n    sum_loss \u003d 0.0\n    correct \u003d 0.0\n    total \u003d 0.0\n    for i, data in enumerate(trainloader, 0):\n        # 准备数据\n        length \u003d len(trainloader)\n        inputs, labels \u003d data\n        inputs, labels \u003d inputs.cuda(), labels.cuda()\n        optimizer.zero_grad()\n        # forward + backward\n        outputs \u003d net(inputs)\n        loss \u003d criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        # 每训练1个batch打印一次loss和准确率\n        sum_loss +\u003d loss.item()\n        _, predicted \u003d torch.max(outputs.data, 1)\n        total +\u003d labels.size(0)\n        correct +\u003d predicted.eq(labels.data).cpu().sum()\n    print(\u0027[epoch:%d, iter:%d] Loss: %.03f | train accuracy: %.3f%% \u0027\n          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n    # 每训练完一个epoch测试一下准确率\n    print(\"Waiting Test!\")\n    with torch.no_grad():\n        correct \u003d 0\n        total \u003d 0\n        for data in testloader:\n            net.eval()\n            images, labels \u003d data\n            images, labels \u003d images.cuda(), labels.cuda()\n            outputs \u003d net(images)\n            # 取得分最高的那个类 (outputs.data的索引号)\n            _, predicted \u003d torch.max(outputs.data, 1)\n            total +\u003d labels.size(0)\n            correct +\u003d (predicted \u003d\u003d labels).sum()\n        print(\u0027test accuracy：%.3f%%\u0027 % (100 * correct / total))\n            #acc \u003d 100. * correct / total",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "cells": []
}