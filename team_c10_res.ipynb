{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"team_c10_res.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0_j6aNCxrbRj","colab_type":"code","outputId":"412c9642-1a73-4b14-8813-82b94e279278","executionInfo":{"status":"ok","timestamp":1563817327520,"user_tz":-480,"elapsed":31281,"user":{"displayName":"Zhenghan Fang","photoUrl":"https://lh4.googleusercontent.com/-7x6JGRALfqo/AAAAAAAAAAI/AAAAAAAAABs/xXVsivNtYu8/s64/photo.jpg","userId":"04655711113233962573"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sun Jul 21 21:17:48 2019\n","\n","@author: Junfeng Hu\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import argparse\n","import matplotlib.pyplot as plt\n","#from resnet import ResNet18\n","import torch.nn.functional as F\n","CUDA_VISIBLE_DEVICES=(2)\n","# 定义是否使用GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# 参数设置,使得我们能够手动输入命令行参数\n","if 0:\n","    parser = argparse.ArgumentParser(description='PyTorch MNIST Training')\n","    parser.add_argument('--outf', default='./model/', help='folder to output images and model checkpoints') #输出结果保存路径\n","    parser.add_argument('--net', default='./model/Resnet18.pth', help=\"path to net (to continue training)\")  #恢复训练时的模型路径\n","    args = parser.parse_args()\n","\n","# 超参数设置\n","EPOCH = 1   #遍历数据集次数\n","pre_epoch = 0  # 定义已经遍历数据集的次数\n","BATCH_SIZE = 32      #批处理尺寸(batch_size)\n","LR = 0.001        #学习率\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, inchannel, outchannel, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.left = nn.Sequential(\n","            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel)\n","        )\n","        self.shortcut = nn.Sequential()\n","         # 如果输入和输出的通道不一致，或其步长不为 1，需要将二者转成一致\n","        if stride != 1 or inchannel != outchannel:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outchannel)\n","            )\n","\n","    def forward(self, x):\n","        out = self.left(x)\n","        out += self.shortcut(x)# 输出 + 输入\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, ResidualBlock, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.inchannel = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        #ResNet 包含多个 layer, 每个 layer 又包含多个 residual block (上面实现的类)\n","        #因此, 用 ResidualBlock 实现 Residual 部分，用 _make_layer 函数实现 layer\n","        #四个 layer， 对应 2， 3， 4， 5 层， 每层有两个 residual block\n","        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n","        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n","        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n","        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n","        # 最后的全连接，分类时使用\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def make_layer(self, block, channels, num_blocks, stride):\n","        #构建 layer, 每一个 layer 由多个 residual block 组成\n","        #在 ResNet 中，每一个 layer 中只有两个 residual block\n","        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.inchannel, channels, stride))\n","            self.inchannel = channels\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        # 最开始的处理\n","        out = self.conv1(x)\n","        # 四层 layer\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        # 全连接 输出分类信息\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","\n","def ResNet18():\n","\n","    return ResNet(ResidualBlock)\n","\n","def train():\n","    # 准备数据集并预处理\n","    transform = transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32\n","        transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.49],\n","                                 std=[1])])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='CIFAR10/', train=True, download=True, transform=transform) #训练数据集\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)   #生成一个个batch进行批训练，组成batch的时候顺序打乱取\n","\n","    testset = torchvision.datasets.CIFAR10(root='CIFAR10/', train=False, download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n","\n","    # 模型定义-ResNet\n","    net = ResNet18().cuda()\n","\n","    # 定义损失函数和优化方式\n","    criterion = nn.CrossEntropyLoss()  #损失函数为交叉熵，多用于多分类问题\n","    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) #优化方式为mini-batch momentum-SGD，并采用L2正则化（权重衰减）\n","\n","    # 训练\n","\n","    test_losses = []\n","    test_acces = []\n","    losses = []\n","    acces = []\n","\n","\n","    for epoch in range(pre_epoch, EPOCH):\n","        print('\\nEpoch: %d' % (epoch + 1))\n","        net.train()\n","        sum_loss = 0.0\n","        correct = 0.0\n","        total = 0.0\n","\n","        train_loss=0\n","        flag=0\n","        for epoch in range(EPOCH):\n","            for step, (inputs,labels) in enumerate(trainloader):\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","                output = net(inputs)\n","                loss = criterion(output, labels)\n","                losses.append(loss.item())\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                total = labels.size(0)\n","                _, predicted = torch.max(output.data, 1)\n","                correct = (predicted == labels).sum().item()\n","                acces.append(correct / total)\n","\n","                #if step % 300 ==0:\n","                print('Epoch:', epoch, '|Step:', step,  \n","                  '|train loss:%.4f'%loss.data.item())\n","                acc,los = test(net, trainloader)\n","                print('Epoch', epoch, '|step ', step, 'loss: %.4f' %los.item(), 'test accuracy:%.4f' %acc)\n","                test_acces.append(acc)\n","                test_losses.append(los.item())\n","                if step == 120:\n","                  flag=1\n","                  break\n","            if flag==1:\n","              break\n","    print('Finished Training')\n","\n","    plt.plot(losses)\n","    plt.plot(test_losses)\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train','test'], loc='upper left')\n","    plt.show()\n","\n","    plt.plot(acces)\n","    plt.plot(test_acces)\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train','test'], loc='upper left')\n","    plt.show()\n","    \n","def test(net, testdata):\n","    criterion = nn.CrossEntropyLoss()\n","    correct, total = .0, .0\n","    net.eval()\n","    for inputs, labels in testdata:\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        outputs = net(inputs)\n","        los = criterion(outputs, labels)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum()\n","    net.train()\n","    return float(correct) / total ,los\n","\n","if __name__ == '__main__':\n","    net = train()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","\n","Epoch: 1\n","Epoch: 0 |Step: 0 |train loss:2.3657\n","Epoch 0 |step  0 loss: 2.3106 test accuracy:0.1000\n","Epoch: 0 |Step: 1 |train loss:2.3547\n","Epoch 0 |step  1 loss: 2.3042 test accuracy:0.1000\n","Epoch: 0 |Step: 2 |train loss:2.3630\n","Epoch 0 |step  2 loss: 2.3033 test accuracy:0.1000\n","Epoch: 0 |Step: 3 |train loss:2.3427\n","Epoch 0 |step  3 loss: 2.3091 test accuracy:0.1000\n","Epoch: 0 |Step: 4 |train loss:2.3178\n","Epoch 0 |step  4 loss: 2.3030 test accuracy:0.1000\n","Epoch: 0 |Step: 5 |train loss:2.3340\n","Epoch 0 |step  5 loss: 2.2861 test accuracy:0.1000\n","Epoch: 0 |Step: 6 |train loss:2.3313\n","Epoch 0 |step  6 loss: 2.3032 test accuracy:0.1000\n","Epoch: 0 |Step: 7 |train loss:2.2934\n","Epoch 0 |step  7 loss: 2.3051 test accuracy:0.1000\n","Epoch: 0 |Step: 8 |train loss:2.2917\n"],"name":"stdout"}]}]}