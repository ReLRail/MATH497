{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "team_c10_vgg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqjuFVdkL7um",
        "colab_type": "code",
        "outputId": "be7dcbc0-3c43-45f3-d1c6-3777247eb86d",
        "executionInfo": {
          "status": "error",
          "timestamp": 1563819561977,
          "user_tz": -480,
          "elapsed": 22144,
          "user": {
            "displayName": "Zhenghan Fang",
            "photoUrl": "https://lh4.googleusercontent.com/-7x6JGRALfqo/AAAAAAAAAAI/AAAAAAAAABs/xXVsivNtYu8/s64/photo.jpg",
            "userId": "04655711113233962573"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "pycharm": {}
      },
      "source": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jul 19 17:45:06 2019\n\n@author: Team 3 \n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport math\nimport torchvision.transforms as transforms\nimport torchvision as tv\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nCUDA_VISIBLE_DEVICES\u003d(7)\nmodel_path \u003d \u0027./model_pth/vgg16_bn-6c64b313.pth\u0027\nBATCH_SIZE \u003d 128\nLR \u003d 0.001\nEPOCH \u003d 5\n\nclass VGG(nn.Module):\n    def __init__(self, features, num_classes\u003d10): \n        super(VGG, self).__init__()\n        self.features \u003d features\n        self.classifier \u003d nn.Sequential( \n            #fc6\n            nn.Linear(256*1*1, 1024),\n            nn.ReLU(),\n            nn.Dropout(),\n \n            #fc7\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Dropout(),\n \n            #fc8\n            nn.Linear(512, num_classes))\n        self._initialize_weights()\n \n    def forward(self, x):\n        x \u003d self.features(x)\n        x \u003d x.view(x.size(0), -1)\n        x \u003d self.classifier(x)\n        return x\n \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n \u003d m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n \n#cfg \u003d [64, 64, \u0027M\u0027, 128, 128, \u0027M\u0027, 256, 256, 256, \u0027M\u0027, 512, 512, 512, \u0027M\u0027, 512, 512, 512, \u0027M\u0027]\n\ncfg \u003d {\n    \u0027A\u0027: [32, 32, \u0027M\u0027, 64, 64, \u0027M\u0027, 128, 128, 128, \u0027M\u0027, 128, 128, 128, \u0027M\u0027, 256, 256, 256, \u0027M\u0027],\n    \u0027B\u0027: [64, 64, \u0027M\u0027, 128, 128, \u0027M\u0027, 256, 256, 256, 256, \u0027M\u0027, 512, 512, 512, 512, \u0027M\u0027, 512, 512, 512, 512, \u0027M\u0027],\n} \n\ndef make_layers(cfg, batch_norm\u003dFalse):\n    layers \u003d []\n    in_channels \u003d 3\n    for v in cfg:\n        if v \u003d\u003d \u0027M\u0027:\n            layers +\u003d [nn.MaxPool2d(kernel_size\u003d2, stride\u003d2)]\n        else:\n            conv2d \u003d nn.Conv2d(in_channels, v, 3, padding\u003d1)\n            if batch_norm:\n                layers +\u003d [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace\u003dTrue)]\n            else:\n                layers +\u003d [conv2d, nn.ReLU(inplace\u003dTrue)]\n            in_channels \u003d v\n    return nn.Sequential(*layers) \n \ndef vgg16(**kwargs):\n    model \u003d VGG(make_layers(cfg[\u0027A\u0027], batch_norm\u003dTrue), **kwargs)\n    #model.load_state_dict(torch.load(model_path))\n    return model\n \ndef getData(): \n    transform \u003d transforms.Compose([\n        transforms.RandomResizedCrop(48),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean\u003d[0.1307],\n                             std\u003d[0.3081])])\n    trainset \u003d tv.datasets.CIFAR10(\n        root\u003d\u0027CIFAR10/\u0027,  \n        train \u003d True , \n        transform \u003d transform,\n        download\u003dTrue,\n        )\n    testset \u003d tv.datasets.CIFAR10(\n        root \u003d \u0027CIFAR10/\u0027, \n        train \u003d False, \n        transform \u003d transform,#tv.transforms.ToTensor(),\n        download \u003d True,\n        )\n    #trainset \u003d tv.datasets.CIFAR10(root\u003d\u0027./root/\u0027, train\u003dTrue, transform\u003dtransform, download\u003dTrue)\n    #testset \u003d tv.datasets.CIFAR10(root\u003d\u0027./root/\u0027, train\u003dFalse, transform\u003dtransform, download\u003dTrue)\n \n    train_loader \u003d DataLoader(trainset, batch_size\u003dBATCH_SIZE, shuffle\u003dTrue)\n    test_loader \u003d DataLoader(testset, batch_size\u003dBATCH_SIZE, shuffle\u003dFalse)\n    return train_loader, test_loader\n \ndef train():\n    trainset_loader, testset_loader \u003d getData()\n    net \u003d vgg16().cuda()\n    net.train()\n \n    # Loss and Optimizer\n    criterion \u003d nn.CrossEntropyLoss()\n    optimizer \u003d torch.optim.Adam(net.parameters(), lr\u003dLR)\n    # Train the model\n    test_losses \u003d []\n    test_acces \u003d []\n    losses \u003d []\n    acces \u003d []\n    flag\u003d0\n    for epoch in range(EPOCH):\n        for step, (inputs,labels) in enumerate(trainset_loader):\n            inputs, labels \u003d inputs.cuda(), labels.cuda()\n            inputs \u003d inputs.cuda()\n            labels \u003d labels.cuda()\n            output \u003d net(inputs)\n            loss \u003d criterion(output, labels)\n            losses.append(loss.item())\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total \u003d labels.size(0)\n            _, predicted \u003d torch.max(output.data, 1)\n            correct \u003d (predicted \u003d\u003d labels).sum().item()\n            acces.append(correct / total)\n            \n            #if step % 300 \u003d\u003d0:\n            print(\u0027Epoch:\u0027, epoch, \u0027|Step:\u0027, step,  \n              \u0027|train loss:%.4f\u0027%loss.data.item())\n            acc,los \u003d test(net, testset_loader)\n            print(\u0027Epoch\u0027, epoch, \u0027|step \u0027, step, \u0027loss: %.4f\u0027 %loss.item(), \u0027test accuracy:%.4f\u0027 %acc)\n            test_acces.append(acc)\n            test_losses.append(los.item())\n        print(\u0027Finished Training\u0027)\n        \n        \n    plt.plot(losses)\n    plt.plot(test_losses)\n    plt.title(\u0027model loss\u0027)\n    plt.ylabel(\u0027loss\u0027)\n    plt.xlabel(\u0027epoch\u0027)\n    plt.legend([\u0027train\u0027,\u0027test\u0027], loc\u003d\u0027upper left\u0027)\n    plt.show()\n\n    plt.plot(acces)\n    plt.plot(test_acces)\n    plt.title(\u0027model accuracy\u0027)\n    plt.ylabel(\u0027accuracy\u0027)\n    plt.xlabel(\u0027epoch\u0027)\n    plt.legend([\u0027train\u0027,\u0027test\u0027], loc\u003d\u0027upper left\u0027)\n    plt.show()\n    \n    \n    return net\n\ndef test(net, testdata):\n    criterion \u003d nn.CrossEntropyLoss()\n    correct, total \u003d .0, .0\n    for inputs, labels in testdata:\n        net.eval()\n        inputs, labels \u003d inputs.cuda(), labels.cuda()\n        inputs \u003d inputs.cuda()\n        labels \u003d labels.cuda()\n        outputs \u003d net(inputs)\n        loss \u003d criterion(outputs, labels)\n        _, predicted \u003d torch.max(outputs, 1)\n        total +\u003d labels.size(0)\n        correct +\u003d (predicted \u003d\u003d labels).sum()\n    net.train()\n    return float(correct) / total ,loss\n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n    net \u003d train()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch: 0 |Step: 0 |train loss:2.3045\n",
            "Epoch 0 |step  0 loss: 2.3045 test accuracy:0.1000\n",
            "Epoch: 0 |Step: 1 |train loss:2.2983\n",
            "Epoch 0 |step  1 loss: 2.2983 test accuracy:0.1000\n",
            "Epoch: 0 |Step: 2 |train loss:2.3095\n",
            "Epoch 0 |step  2 loss: 2.3095 test accuracy:0.1051\n",
            "Epoch: 0 |Step: 3 |train loss:2.3324\n",
            "Epoch 0 |step  3 loss: 2.3324 test accuracy:0.0979\n",
            "Epoch: 0 |Step: 4 |train loss:2.2860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-1-372023d85e51\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;34m\u0027__main__\u0027\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 193\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m\u003cipython-input-1-372023d85e51\u003e\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m             print(\u0027Epoch:\u0027, epoch, \u0027|Step:\u0027, step,  \n\u001b[1;32m    145\u001b[0m               \u0027|train loss:%.4f\u0027%loss.data.item())\n\u001b[0;32m--\u003e 146\u001b[0;31m             \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlos\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u0027Epoch\u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u0027|step \u0027\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u0027loss: %.4f\u0027\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u0027test accuracy:%.4f\u0027\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mtest_acces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m\u003cipython-input-1-372023d85e51\u003e\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net, testdata)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;36m.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 127\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---\u003e 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mnchannel\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 87\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}