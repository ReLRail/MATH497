{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"team_mnist_res.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"H1DXIHw2pPai","colab_type":"code","outputId":"01ed1193-05c9-4324-af84-d8e54bc55f32","executionInfo":{"status":"ok","timestamp":1563815069900,"user_tz":-480,"elapsed":633148,"user":{"displayName":"nixie chen","photoUrl":"","userId":"08771258786301814895"}},"colab":{"base_uri":"https://localhost:8080/","height":867}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Sun Jul 21 21:17:48 2019\n","\n","@author: Team 3 \n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import argparse\n","#from resnet import ResNet18\n","import torch.nn.functional as F\n","CUDA_VISIBLE_DEVICES=(2)\n","# if we need to use the GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# cfg\n","if 0:\n","    parser = argparse.ArgumentParser(description='PyTorch MNIST Training')\n","    parser.add_argument('--outf', default='./model/', help='folder to output images and model checkpoints') #ourput saving address\n","    parser.add_argument('--net', default='./model/Resnet18.pth', help=\"path to net (to continue training)\")  #to continue training address\n","    args = parser.parse_args()\n","\n","\n","EPOCH = 10   \n","pre_epoch = 0  \n","BATCH_SIZE = 64     \n","LR = 0.1        \n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, inchannel, outchannel, stride=1):\n","        super(ResidualBlock, self).__init__()\n","        self.left = nn.Sequential(\n","            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel)\n","        )\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or inchannel != outchannel:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outchannel)\n","            )\n","\n","    def forward(self, x):\n","        out = self.left(x)\n","        out += self.shortcut(x)# output+input\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, ResidualBlock, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.inchannel = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n","        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n","        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n","        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def make_layer(self, block, channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.inchannel, channels, stride))\n","            self.inchannel = channels\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","\n","def ResNet18():\n","\n","    return ResNet(ResidualBlock)\n","\n","\n","\n","transform = transforms.Compose([\n","    transforms.RandomCrop(28, padding=4),  \n","    transforms.RandomHorizontalFlip(), \n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.49],\n","                             std=[1])])\n","\n","trainset = torchvision.datasets.MNIST(root='mnist/', train=True, download=True, transform=transform) \n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)   \n","\n","testset = torchvision.datasets.MNIST(root='mnist/', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n","\n","# ResNet\n","net = ResNet18().cuda()\n","\n","\n","criterion = nn.CrossEntropyLoss()  \n","optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) \n","\n","# train\n","for epoch in range(pre_epoch, EPOCH):\n","    print('\\nEpoch: %d' % (epoch + 1))\n","    net.train()\n","    sum_loss = 0.0\n","    correct = 0.0\n","    total = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # perpare the data\n","        length = len(trainloader)\n","        inputs, labels = data\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","        optimizer.zero_grad()\n","        # forward + backward\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        #print loss and acc once per one batch\n","        sum_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels.data).cpu().sum()\n","    print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n","          % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n","    print(\"Waiting Test!\")\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for data in testloader:\n","            net.eval()\n","            images, labels = data\n","            images, labels = images.cuda(), labels.cuda()\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum()\n","        print('The ACC is ：%.3f%%' % (100 * correct / total))\n","      \n","                    "],"execution_count":3,"outputs":[{"output_type":"stream","text":["\n","Epoch: 1\n","[epoch:1, iter:938] Loss: 0.320 | Acc: 89.000% \n","Waiting Test!\n","The ACC is ：94.000%\n","\n","Epoch: 2\n","[epoch:2, iter:1876] Loss: 0.122 | Acc: 96.000% \n","Waiting Test!\n","The ACC is ：95.000%\n","\n","Epoch: 3\n","[epoch:3, iter:2814] Loss: 0.105 | Acc: 96.000% \n","Waiting Test!\n","The ACC is ：95.000%\n","\n","Epoch: 4\n","[epoch:4, iter:3752] Loss: 0.099 | Acc: 96.000% \n","Waiting Test!\n","The ACC is ：96.000%\n","\n","Epoch: 5\n","[epoch:5, iter:4690] Loss: 0.101 | Acc: 96.000% \n","Waiting Test!\n","The ACC is ：96.000%\n","\n","Epoch: 6\n","[epoch:6, iter:5628] Loss: 0.093 | Acc: 97.000% \n","Waiting Test!\n","The ACC is ：96.000%\n","\n","Epoch: 7\n","[epoch:7, iter:6566] Loss: 0.090 | Acc: 97.000% \n","Waiting Test!\n","The ACC is ：96.000%\n","\n","Epoch: 8\n","[epoch:8, iter:7504] Loss: 0.091 | Acc: 97.000% \n","Waiting Test!\n","The ACC is ：96.000%\n","\n","Epoch: 9\n","[epoch:9, iter:8442] Loss: 0.091 | Acc: 97.000% \n","Waiting Test!\n","The ACC is ：95.000%\n","\n","Epoch: 10\n","[epoch:10, iter:9380] Loss: 0.090 | Acc: 97.000% \n","Waiting Test!\n","The ACC is ：95.000%\n"],"name":"stdout"}]}]}